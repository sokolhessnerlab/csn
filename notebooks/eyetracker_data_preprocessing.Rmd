---
title: "Eyetracker Data Preprocessing"
author: "Ari Dyckovsky"
---

```{r, notebook-options, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  strip.white = TRUE,
  highlight = TRUE,
  warning = FALSE,
  message = FALSE
)

make_pretty_df <- function(df) {
  if (isTRUE(getOption("knitr.in.progress"))) {
    knitr::kable(df, "simple", format.args = list(big.mark = ",", scientific = FALSE))
  } else {
    df
  }
}
```

## Setup

This notebook requires that the following chunks are run before any other section
chunks can resolve. Please complete the following in order:

1. Load the package interface with its dependencies,
2. Load the configuration settings,
3. Set file paths,
4. Set participant identification settings.

### Load package with dependencies

```{r, load-packages}
# Load csn package with devtools
library(devtools)
load_all()

# Load dependencies
library(tidyverse)
library(rlang)
library(ggpubr)
```

### Load configuration settings

We use a configuration file called `config.yml` to handle environment settings,
such as the absolute path to data and subdirectories by type of data (i.e., "raw")
and participant identification details (i.e., the prefix "CSN"). For more information
on how to use configurable environment settings, see [this introduction vignette](https://cran.r-project.org/web/packages/config/vignettes/introduction.html).

```{r, load-config}
config <- config::get()
```

### File path definitions

File path definitions are set using configured environment settings from
the `config.yml` file. (Note: overrides of configured settings should occur
within the YAML text file, usually via a new environment that inherits
defaults other than explicit overrides).

```{r, file-path-definitions}
# Top level data path for entry
data_path <- config$path$data

# Extracted data subdirectory path
extracted_data_path <- file.path(
  data_path,
  config$path$extracted
)

# Extracted eyetracker data subdirectory path
extracted_eyetracker_data_path <- file.path(
  extracted_data_path,
  config$path$eyetracker
)

# Extracted behavioral data subdirectory path
extracted_behavioral_data_path <- file.path(
  extracted_data_path,
  config$path$behavioral
)

# Extracted eyetracker data file names (to CSV, from MAT)
event_csv <- config$extracted_files$eyetracker_event_csv
sample_csv <- config$extracted_files$eyetracker_sample_csv
ioevent_csv <- config$extracted_files$eyetracker_ioevent_csv
recordings_csv <- config$extracted_files$eyetracker_recordings_csv
```

### Participant identification settings

Participant identification settings are also use configured environment settings from
the `config.yml` file.

```{r, participant-id-settings}
# Participant id settings
participant_id_prefix <- config$participant_id$prefix
participant_id_pad_length <- config$participant_id$pad_length
participant_id_pad_character <- config$participant_id$pad_character
participant_id_min <- config$participant_id$min
participant_id_max <- config$participant_id$max
```

## Load extracted data

### Define loading methods for CSVs

```{r, define-loading-methods}
min_id <- participant_id_min
max_id <- participant_id_max

get_path_to_id <- function(path_to_dir, id) {
  padded_id <- stringr::str_pad(id,
    participant_id_pad_length,
    pad = participant_id_pad_character
  )
  participant_id <- stringr::str_c(participant_id_prefix, padded_id)
  return(
    file.path(
      path_to_dir,
      participant_id
    )
  )
}

get_id_vector <- function(path_to_dir) {
  # Gets a vector of id integers for participants relative
  # to the existence of that participant's data (some participants
  # are not converted from raw MAT data to CSVs if not considered
  # a complete participant)
  id_vector <- c()
  for (i in min_id:max_id) {
    if (dir.exists(get_path_to_id(path_to_dir, i))) {
      id_vector <- c(id_vector, i)
    }
  }
  return(id_vector)
}

#' Read a directory of files, or directory of directories of files specifying
#' a specific commanly-named file, into a dataframe list.
#'
#' @param path_to_dir A path string to a directory of CSV data
#' @param id_vector A vector of participant IDs as integers
#' @param filename_csv A string name for a file type, including extension.
#'
#' @examples
#' load_participant_data(extracted_eyetracker_data_path, id_vector, event_csv)
load_participant_data <- function(path_to_dir, id_vector, filename_csv) {
  # TODO: Include column specfications by type of loading.
  if ("df" %in% ls()) rm("df")
  df <- data.frame()

  df_list <- list()

  for (id in id_vector) {
    if (is_missing(filename_csv)) {
      # Path to file of the participant data as a CSV, such as `path/to/CSN004.csv`.
      path_to_file <- stringr::str_c(get_path_to_id(path_to_dir, id), ".csv")
    } else {
      # Path to files nested within a participant-identified directory, such
      # as with eyetracking data that is split into multiple CSVs, which may
      # be `path/to/CSN004/data.csv`.
      path_to_file <- file.path(get_path_to_id(path_to_dir, id), filename_csv)
    }

    df <- readr::read_csv(path_to_file)
    df_list[[id]] <- df
  }

  return(df_list)
}

# Convenience instantiation of the id vector for later use. Can use
# the getter method at any point for same output. Note: This uses the
# extracted eyetracker data path.
id_vector <- get_id_vector(extracted_eyetracker_data_path)
```

### Load eyetracking data for each participant

The following chunk loads CSVs for participants' event, recordings, and sample data
and then assigns a list of these loaded dataframes to the approriate `etd_*` variable.

```{r, load-etd-lists, message=FALSE}
etd_events <- load_participant_data(extracted_eyetracker_data_path, id_vector, event_csv)
etd_recordings <- load_participant_data(extracted_eyetracker_data_path, id_vector, recordings_csv)
etd_samples <- load_participant_data(
  extracted_eyetracker_data_path,
  id_vector,
  sample_csv
)
```

### Load all behavioral data for each participant

The following chunk loads CSVs for participants' behavioral data data
and then assigns a list of these loaded dataframes to `behavioral_df_list`.

``````{r, load-behavioral-list, message=FALSE}
behavioral_df_list <- load_participant_data(extracted_behavioral_data_path, id_vector)
```

## Events data

### Methods using `etd_events` list of loaded dataframes

```{r, events-data-methods}
CALIBRATION_RESULT_MESSAGE <- "!CAL CALIBRATION HV9 R RIGHT"
VALIDATION_RESULT_MESSAGE <- "!CAL VALIDATION HV9 R RIGHT"
CATEGORY_STRING_PATTERN <- "CALIBRATION|VALIDATION"
QUALITY_STRING_PATTERN <- "GOOD|FAIR|POOR"
AVG_ERROR_STRING_INDEX <- 8
MAX_ERROR_STRING_INDEX <- 10
DEG_OFFSET_STRING_INDEX <- 13
PIX_OFFSET_STRING_INDEX <- 15


get_category_from_message <- function(message) {
  # Extract the category of event message
  as.character(str_extract(message, CATEGORY_STRING_PATTERN))
}


get_quality_from_message <- function(message) {
  # Extract the quality of calibration or validation from event message
  as.character(str_extract(message, QUALITY_STRING_PATTERN))
}


get_avg_error_from_message <- function(message) {
  # Extract the avg error of validation
  as.double(word(message, AVG_ERROR_STRING_INDEX))
}


get_max_error_from_message <- function(message) {
  # Extract the max error of validation
  as.double(word(message, MAX_ERROR_STRING_INDEX))
}


get_deg_offset_from_message <- function(message) {
  # Extract the deg offset of validation
  as.double(word(message, DEG_OFFSET_STRING_INDEX))
}


get_pix_offset_from_message <- function(message) {
  # Extract the x coordinate of pix offset of validation
  word(message, PIX_OFFSET_STRING_INDEX)
}


get_event_messages <- function(participant_events) {
  # Get the significant event messages for a single participant
  # events data by sttime, producing the extracted rows and columns
  # from message contents.

  if ("df" %in% ls()) rm("df")

  # Select desired columns and remove white space around message
  df <- participant_events %>%
    select(message, sttime) %>%
    transmute(message = str_squish(str_trim(message)), sttime = sttime)

  # Extract rows from categorized event result messages
  df <- df %>%
    filter(
      str_detect(message, CALIBRATION_RESULT_MESSAGE) |
        str_detect(message, VALIDATION_RESULT_MESSAGE)
    ) %>%
    mutate(
      category = get_category_from_message(message),
      quality = get_quality_from_message(message),
      avg_error = get_avg_error_from_message(message),
      max_error = get_max_error_from_message(message),
      deg_offset = get_deg_offset_from_message(message),
      pix_offset = get_pix_offset_from_message(message)
    )

  # Extract columns for pixel offsets of x,y coordinates
  df <- df %>%
    separate(pix_offset, c("pix_x_offset", "pix_y_offset"), ",") %>%
    mutate(
      pix_x_offset = as.double(pix_x_offset),
      pix_y_offset = as.double(pix_y_offset)
    )

  # Move message column to last column for convenient notebook
  # reading of dataframe output
  df <- df %>%
    relocate(-message)

  return(df)
}
```

Output of a single participant's calibration/validation event data.

```{r, calibration-validation-event-data-example}
make_pretty_df(
  get_event_messages(etd_events[[5]])
)
```

## Recordings data

### Methods using `etd_recordings` list of loaded dataframes

```{r, recordings-data-methods}
get_duration <- function(id) {
  # Duration from highest start time and lowest start time, in minutes
  summary <- etd_recordings[[id]] %>%
    summarize(duration = (max(time) - min(time)) / (1000 * 60)) %>%
    unnest(cols = c())
  return(summary$duration)
}

get_durations <- function(id_vector) {
  # Durations in minutes for all participants events' data
  durations <- c()
  for (i in id_vector) {
    durations <- c(durations, get_duration(i))
  }
  return(durations)
}

get_recording_time_matrix <- function(id_vector, dimensional_reducer = 1) {
  # Get a built matrix with a row for each id in id_vector, with four
  # times per row. Optional dimensional reducer to achieve times in seconds, minutes.
  n_ids <- length(id_vector)
  n_recordings <- 1 + length(etd_recordings[[id_vector[[1]]]]$time)
  recording_time_matrix <- matrix(NA, nrow = n_ids, ncol = n_recordings)

  for (i in 1:n_ids) {
    id <- id_vector[i]
    recording_time_matrix[i, ] <- c(id, (etd_recordings[[id]]$time / dimensional_reducer))
  }

  return(recording_time_matrix)
}

get_recording_time_df <- function(id_vector, dimensional_reducer = 1) {
  # Get dataframe using matrix of ids and times from recordings. Optional
  # dimensional reducer to achieve times in seconds, minutes.
  m <- get_recording_time_matrix(id_vector, dimensional_reducer)
  df <- as.data.frame(m)
  recording_time_df_cols <- c("id", "calibration", "validation", "task", "revalidation")
  colnames(df) <- recording_time_df_cols

  return(df)
}
```

### Look at recording times

Can retrieve all recording moments across participants by seconds or minutes. In seconds, the difference between revalidation and task time, then subtracting 3600, provides an idea of how much "overtime" the task went.

```{r, look-at-recording-times}
recording_time_df_seconds <- get_recording_time_df(id_vector, 1000)
recording_time_df_minutes <- get_recording_time_df(id_vector, 1000 * 60)

sort(recording_time_df_seconds$revalidation - recording_time_df_seconds$task - 3600)
```

## Evaluate validation and revalidation quality

### Methods to create validation and revalidation dataframes

```{r, joint-data-methods}
get_val_reval_by_id <- function(recording_time_df, i) {
  recording_times_for_id <- recording_time_df %>%
    filter(id == i)

  all_validations_by_id <- get_event_messages(etd_events[[i]]) %>%
    filter(category == "VALIDATION") %>%
    select(-c(message, category))

  validation <- all_validations_by_id %>%
    filter(sttime < recording_times_for_id$task) %>%
    arrange(sttime) %>%
    slice_tail(n = 1) %>%
    mutate(id = as.integer(i)) %>%
    relocate(id) %>%
    rename_with(~ paste(.x, "val", sep = "_"), -id)

  revalidation <- all_validations_by_id %>%
    filter(sttime > (recording_times_for_id$task + 60 * 60 * 1000)) %>%
    arrange(sttime) %>%
    slice_tail(n = 1) %>%
    mutate(id = as.integer(i)) %>%
    relocate(id) %>%
    rename_with(~ paste(.x, "reval", sep = "_"), -id)

  left_join(
    validation,
    revalidation,
    by = c("id")
  )
}

get_all_val_reval_df <- function(id_vector) {
  if ("df" %in% ls()) rm("df")

  df <- data.frame()

  recording_time_df <- get_recording_time_df(id_vector)

  for (i in id_vector) {
    val_reval_df <- get_val_reval_by_id(recording_time_df, i)
    df <- bind_rows(df, val_reval_df)
  }

  return(df)
}

get_recording_and_val_reval_df <- function(recording_time_df, all_val_reval_df) {
  left_join(
    recording_time_df,
    all_val_reval_df,
    by = c("id")
  )
}
```

#### Combine recording times with significant event details per participant

```{r, combine-recording-events, message=FALSE}
recording_time_df <- get_recording_time_df(id_vector)
all_val_reval_df <- get_all_val_reval_df(id_vector)

recording_and_val_reval_df <- get_recording_and_val_reval_df(recording_time_df, all_val_reval_df)
```

Visulaize the head of the dataframe:

```{r, show-table-recording-and-val-reval}
make_pretty_df(
  head(recording_and_val_reval_df, 10)
)
```

Mutate to get change in average error, max error, and pixel offsets. 

```{r, validation-revaliation-changes-dataframe}
get_val_reval_changes_df <- function(recording_time_df, all_val_reval_df) {
  
  # Get recording times for validation and revalidation
  recording_and_val_reval_df <- get_recording_and_val_reval_df(
    recording_time_df,
    all_val_reval_df
  )
  
  # Mutate and relocate error and offset data, then arrange
  # by absolute value of average error change
  val_reval_changes_df <- recording_and_val_reval_df %>%
    mutate(
      avg_error_change = avg_error_reval - avg_error_val,
      max_error_change = max_error_reval - max_error_val,
      pix_x_offset_change = pix_x_offset_reval - pix_x_offset_val,
      pix_y_offset_change = pix_y_offset_reval - pix_y_offset_val
    ) %>%
    relocate(
      c(
        avg_error_change,
        max_error_change,
        pix_x_offset_change,
        pix_y_offset_change
      ),
      .after = id
    ) %>%
    arrange(abs(avg_error_change))
}

val_reval_changes_df <- get_val_reval_changes_df(
  recording_time_df,
  all_val_reval_df
)

make_pretty_df(
  val_reval_changes_df
)
```

### Correlation tests for `avg_error` and `max_error`

Compare the average error between validation and revalidation across
participants using a Pearson's product-moment correlation. Do the same for max error.

```{r, avg-max-error-corr-tests}
low_avg_error_df <- val_reval_changes_df %>%
  filter(avg_error_change < 7)

avg_error_corr <- cor.test(
  low_avg_error_df$avg_error_val,
  low_avg_error_df$avg_error_reval,
  method = "pearson",
  use = "complete.obs"
)

max_error_corr <- cor.test(
  low_avg_error_df$max_error_val,
  low_avg_error_df$max_error_reval,
  method = "pearson",
  use = "complete.obs"
)

avg_error_corr
max_error_corr
```

### Methods for correlation plots

```{r,corr-plot-methods}
get_error_correlation_plot <- function(df, measure) {
  ggscatter(
    data = df,
    x = str_glue("{ measure }_error_val"),
    y = str_glue("{ measure }_error_reval"),
    add = "reg.line",
    add.params = list(color = "blue", fill = "lightgray"),
    conf.int = TRUE
  ) +
    coord_fixed(ratio = 1) +
    geom_abline() +
    stat_cor(method = "pearson") +
    theme_classic2() +
    labs(
      title = tools::toTitleCase(str_glue("Correlation of { measure } error between validation and revalidation")),
      x = tools::toTitleCase(str_glue("{ measure } Error of Validation")),
      y = tools::toTitleCase(str_glue("{ measure } Error of Revalidation"))
    )
}

get_offset_correlation_plot <- function(df, measure) {
  ggscatter(
    data = df,
    x = str_glue("pix_{ measure }_offset_val"),
    y = str_glue("pix_{ measure }_offset_reval"),
    add = "reg.line",
    add.params = list(color = "blue", fill = "lightgray"),
    conf.int = TRUE
  ) +
    stat_cor(method = "pearson") +
    theme_classic2() +
    labs(
      title = tools::toTitleCase(str_glue("Pixel offset ({ measure }) changes between validation and revalidation")),
      x = tools::toTitleCase(str_glue("{ measure } Offset in Validation (px)")),
      y = tools::toTitleCase(str_glue("{ measure } Offset in Revalidation (px)"))
    )
}

get_offset_boxplot <- function(df, group, measure) {
  ggboxplot(
    data = df,
    x = str_glue("{ group }"),
    y = str_glue("{ measure }"),
    color = str_glue("{ group }"),
    order = c("val", "reval")
  ) +
    theme_classic2() +
    labs(
      title = tools::toTitleCase(str_glue("Pixel offset ({ measure }) from validation to revalidation"))
    )
}
```

```{r, avg-error-corr-plot}
get_error_correlation_plot(val_reval_changes_df, "avg")
```


```{r, max-error-corr-plot}
get_error_correlation_plot(val_reval_changes_df, "max")
```

### Categorized dataframes by validation and revalidation conditions

Create a categorized offset dataframe and then show and example of it.

```{r, categorized-offset-dataframe}
categorized_offset_df <- val_reval_changes_df %>%
  select(id, matches("pix"), -matches("change")) %>% # remove offset change columns
  pivot_longer(
    cols = -c(id), # don't select for id
    names_to = c(".value", "category"),
    names_pattern = "pix_(.)_offset_(.*)"
  ) %>%
  group_by(id) %>%
  mutate(
    distance = sqrt(x^2 + y^2)
  ) %>%
  mutate(
    x_change = x[category == "reval"] - x[category == "val"],
    y_change = y[category == "reval"] - y[category == "val"],
    distance_change = distance[category == "reval"] - distance[category == "val"]
  )

make_pretty_df(
  head(categorized_offset_df)
)
```

Create a categorized error dataframe and then show an example of it.

```{r, categorized-error-dataframe}
categorized_error_df <- val_reval_changes_df %>%
  select(id, matches("error"), -matches("change")) %>% # remove offset change columns
  pivot_longer(
    cols = -c(id), # don't select for id
    names_to = c(".value", "category"),
    names_pattern = "(.*)_error_(.*)"
  ) %>%
  group_by(id) %>%
  mutate(
    avg_change = avg[category == "reval"] - avg[category == "val"],
    max_change = max[category == "reval"] - max[category == "val"]
  )

make_pretty_df(
  head(categorized_error_df)
)
```

Look at the participants who have decreasing average errors over the course
of the task.

```{r}
make_pretty_df(
  categorized_error_df %>%
    filter(avg_change < 0)
)
```

#### Shapiro-Wilk normality tests

By results of Shapiro-Wilk normality test for the x offset (p < 0.05), we may
reject the normality hypothesis, so should use the paired samples Wilcoxon
test. Regarding y offset (p = 0.41), we can assume normality and run a paired
samples t-test.

```{r}
shapiro.test(val_reval_changes_df$pix_x_offset_change)
shapiro.test(val_reval_changes_df$pix_y_offset_change)
```

Then, using the categorized offset dataframe, apply test to distance
calculated via norming (x,y) and origin. It's very likely the distances
from betweeen validation and revalidation are not normally distributed (p << 0.05).

```{r}
shapiro.test(categorized_offset_df$distance)
```

#### Paired samples Wilcoxon test for x offset:

```{r}
wilcox.test(
  x = val_reval_changes_df$pix_x_offset_val,
  y = val_reval_changes_df$pix_x_offset_reval,
  paired = TRUE
)
```

```{r}
get_offset_boxplot(df = categorized_offset_df, group = "category", measure = "x")
```

#### Paired samples t-test for y offset

```{r}
t.test(
  x = val_reval_changes_df$pix_y_offset_val,
  y = val_reval_changes_df$pix_y_offset_reval,
  paired = TRUE
)
```

```{r}
get_offset_boxplot(df = categorized_offset_df, group = "category", measure = "y")
```

#### Paired samples Wilcoxon test for distance

```{r}
wilcox.test(
  distance ~ category,
  data = categorized_offset_df,
  paired = TRUE
)
```

```{r}
get_offset_boxplot(df = categorized_offset_df, group = "category", measure = "distance")
```

### Paired Plots

### Paired plots for validation-revalidation changes

Plot the change in average error with gradient coloring for the slope
of average error change.

```{r, offset-change-paired-plots-method}
make_paired_plot <- function(categorized_df, measure) {
  # requires a categorized dataframe, the category column selector, and measure (str)
  plt <- categorized_df %>%
    ggplot(aes(x = factor(category, level = c("val", "reval")), y = !!sym(measure), group = id)) +
    geom_point(size = 1, alpha = 0.5) +
    geom_line(alpha = 0.6, aes(color = !!sym(str_glue("{ measure }_change")))) +
    scale_color_gradient2(low = "red", mid = "gray", high = "blue")
  return(plt)
}
```

#### Offset changes

```{r, offset-change-paired-plots}
make_paired_plot(categorized_offset_df,
  measure = "x"
) +
  labs(
    title = "Change in X Offset between Validation and Revalidation",
    # subtitle = "Only Decreases in Average Error",
    x = "Event Category",
    y = "X Offset (pixels)"
  ) +
  theme_classic2()

make_paired_plot(categorized_offset_df,
  measure = "y"
) +
  labs(
    title = "Change in Y Offset between Validation and Revalidation",
    # subtitle = "Only Decreases in Average Error",
    x = "Event Category",
    y = "Y Offset (pixels)"
  ) +
  theme_classic2()

make_paired_plot(categorized_offset_df,
  measure = "distance"
) +
  labs(
    title = "Change in Distance Offset between Validation and Revalidation",
    # subtitle = "Only Decreases in Average Error",
    x = "Event Category",
    y = "Distance Offset (pixels)"
  ) +
  theme_classic2()
```

#### Average error changes

```{r, error-change-paired-plot}
make_paired_plot(categorized_error_df %>% filter(avg_change < 0),
  measure = "avg"
) +
  labs(
    title = "Change in Avg Error between Validation and Revalidation",
    subtitle = "Only Decreases in Average Error",
    x = "Event Category",
    y = "Avg Error"
  ) +
  theme_classic2()

make_paired_plot(categorized_error_df %>% filter(avg_change > 0),
  measure = "avg"
) +
  labs(
    title = "Change in Avg Error between Validation and Revalidation",
    subtitle = "Only Increases in Average Error",
    x = "Event Category",
    y = "Avg Error"
  ) +
  theme_classic2()

make_paired_plot(categorized_error_df %>% filter(id != 11),
  measure = "avg"
) +
  labs(
    title = "Change in Avg Error between Validation and Revalidation",
    subtitle = "Only Increases in Average Error",
    x = "Event Category",
    y = "Avg Error"
  ) +
  theme_classic2()
```

## Behavioral data

### Clock sides

Get the clock sides for each participant and create a dataframe of
their id and side values.

```{r, clock-sides}
CLOCK_LEFT <- 0
CLOCK_RIGHT <- 1

get_clock_sides <- function(behavioral_df_list) {
  if ("df" %in% ls()) rm("df")
  df <- data.frame(id = integer(), side = integer())

  for (i in id_vector) {
    side <- behavioral_df_list[[i]] %>%
      slice(1) %>%
      pull(clock_side)
    df <- df %>% dplyr::add_row(tibble(id = i, side))
  }

  return(df)
}

clock_sides_df <- get_clock_sides(behavioral_df_list)

# Count of left and right clock sides
make_pretty_df(
  head(
    clock_sides_df %>%
      group_by(side) %>%
      count()
  )
)
```

## Samples data

```{r, preview-sample}
make_pretty_df(
  head(etd_samples[[4]], 20)
)
```

### Constants

```{r}
MILLISECONDS_PER_HOUR <- 3600000
MILLISECONDS_PER_SECONDS <- 1000
SCREEN_WIDTH_PX <- 1280
SCREEN_HEIGHT_PX <- 1024
SCREEN_BIN_WIDTH_PX <- 16
SCREEN_CENTER_COORD <- c(SCREEN_WIDTH_PX / 2, SCREEN_HEIGHT_PX / 2)

GX_SAMPLE_ERROR_VALUE <- 10^7
GY_SAMPLE_ERROR_VALUE <- 10^7
```

### Extract samples for task duration

```{r, task-gaze-samples}
# get the task start time from recordings data embedded in cleaned
# val_reval changes dataframe
get_task_start_time <- function(val_reval_changes_df, i) {
  task_start_time <- val_reval_changes_df %>%
    filter(id == i) %>%
    pull(task)
}

# Filter sample data per participant for the hour duration
# from start to end of task, then translate and transform
# frame of reference for time to start at 0 in seconds. Remove
# all error values for gaze sample and plot
get_task_gaze_df <- function(etd_samples, val_reval_changes_df, id) {
  task_start_time <- get_task_start_time(val_reval_changes_df, id)
  task_gaze_df <- etd_samples[[id]] %>%
    filter(time >= task_start_time & time < task_start_time + MILLISECONDS_PER_HOUR) %>%
    mutate(time = (time - time[[1]]) / MILLISECONDS_PER_SECONDS) %>%
    filter(gx < GX_SAMPLE_ERROR_VALUE & gy < GY_SAMPLE_ERROR_VALUE)
  return(task_gaze_df)
}

# Get list of task gaze dataframes
get_task_gaze_df_list <- function(etd_samples, id_vector) {
  
  val_reval_changes_df <- get_val_reval_changes_df(
    recording_time_df,
    all_val_reval_df
  )
  
  if ("df" %in% ls()) rm("df")
  df <- data.frame()
  
  df_list <- list()

  for (id in id_vector) {
    df <- get_task_gaze_df(etd_samples, val_reval_changes_df, id)
    df_list[[id]] <- df
  }

  return(df_list)
}

task_gaze_df_list <- get_task_gaze_df_list(etd_samples, id_vector)
```

### Flip right-side clocks to left side

```{r}
reflect_over_midpoint <- function(point, midpoint) {
  return(2 * midpoint - point)
}

right_clocks_df <- clock_sides_df %>%
  filter(side == CLOCK_RIGHT)

right_clocks_df
#task_gaze_df_list[[2]] %>%
#  mutate(gx = reflect_over_midpoint(gx, SCREEN_CENTER_COORD[[1]]))
```

```{r, plot-heatmap-task-gaze}
FIXED_ID <- 4

task_gaze_df <- task_gaze_df_list[[FIXED_ID]]

plt <- ggplot(task_gaze_df, aes(x = gx, y = gy)) +
  # xlim(0, SCREEN_WIDTH_PX) +
  # ylim(0, SCREEN_HEIGHT_PX) +
  theme_minimal() +
  labs(
    title = str_glue("Heatmap of gaze samples across task duration for CSN{ str_pad(FIXED_ID, 3, pad = '0') }")
  )

# add clock circle in
# flip all participants to same orientation (all left, or all right, but not both)

# Validate translations for pixel offset, point by point
# 1. clock on left
# 2. Cut data from non-clock side/half
# 3. Average distance from clock hand's tip per timestamp
# 4. Offset of x,y from val/reval is the translation, use mean of two values for each orientation
# 5. Compare distance from clock with and without correction by offset
# 6. Worth looking at quartiles of average distance per participant
# 7. Then plot average distance for each participant in a plot
#
# See matlab task code to see where tip of clock hand is at every second
plt + geom_bin2d(binwidth = c(SCREEN_BIN_WIDTH_PX, SCREEN_BIN_WIDTH_PX))
```

## Exclusions by threshold of 2.5 degrees

```{r}
make_pretty_df(
  val_reval_changes_df %>%
    filter(avg_error_val >= 2.5 | avg_error_reval >= 2.5)
)
```


```{r}
df <- val_reval_changes_df %>%
  filter(avg_error_val < 2.5 & avg_error_reval < 2.5)

t.test(df$avg_error_change, mu = 0)
```


